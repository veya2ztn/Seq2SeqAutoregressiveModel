{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19b7a7c",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61917ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.afnonet import AFNONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b94f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import getModelSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84624ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfb9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AFNONet((32,64),2,70,70,768,history_length=6,unique_up_sample_channel=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d485a2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.unique_up_sample_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec19a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltool.universal_model_util import get_model_para_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96424c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of Parameters: 72391391, Number of Buffers: 0, Size of Model: 276.1512 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_sum, buffer_sum, all_size = getModelSize(model)\n",
    "print(f\" Number of Parameters: {param_sum}, Number of Buffers: {buffer_sum}, Size of Model: {all_size:.4f} MB\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074816d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.patch_model import NaiveConvModel2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad10412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a533b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveConvModel2D((32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35a1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,20,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653c093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import get_center_around_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389817cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape=(32,64)\n",
    "patch_range=5\n",
    "center_index,around_index=get_center_around_indexes(patch_range,img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38dad203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 64, 2, 5, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "around_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20928164",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_range=5\n",
    "delta = [list(range(-(patch_range//2),patch_range//2+1))]*2\n",
    "delta = np.meshgrid(*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92177012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "250fd2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00dc0f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4, 2, 3, 4, 2, 3, 4],\n",
       "       [2, 2, 2, 3, 3, 3, 4, 4, 4]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = [list(range(-(patch_range//2),patch_range//2+1))]*len(center)\n",
    "delta = np.meshgrid(*delta)\n",
    "pos  = [c+dc for c,dc in zip(center,delta)]\n",
    "pos[-1]= pos[-1]%64\n",
    "\n",
    "px = x + dx\n",
    "py = y + dy\n",
    "np.stack([px.flatten(),py.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "004d72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fbeda73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2  3  4  5]\n",
      "   [ 6  7  8  9 10 11]\n",
      "   [12 13 14 15 16 17]\n",
      "   [18 19 20 21 22 23]\n",
      "   [24 25 26 27 28 29]\n",
      "   [30 31 32 33 34 35]]]]\n"
     ]
    }
   ],
   "source": [
    "coordinate = np.arange(36).reshape(1,1,6,6)\n",
    "print(coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f245c1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2, 3, 3, 6)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinate[:,:,pos].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a71673fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[[14 20 26]\n",
      " [15 21 27]\n",
      " [16 22 28]]\n"
     ]
    }
   ],
   "source": [
    "print(coordinate[:,:,x,y][0,0])\n",
    "print(coordinate[:,:,pos[0],pos[1]][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c7465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.FEDformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66615d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19f42098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg_spacetime(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size)==3\n",
    "        self.kernel_size = np.array(kernel_size)\n",
    "        self.avg         = nn.AvgPool3d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "        self.pad_front   = self.kernel_size - 1-np.floor((self.kernel_size - 1) // 2)\n",
    "        self.pad_end     = np.floor((self.kernel_size - 1) // 2)\n",
    "        self.pad         = np.stack([self.pad_front,self.pad_end],1)[::-1].flatten().astype('int').tolist()\n",
    "        print(self.pad)\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        # the input must be (B,*Space,T,C)， the -1 dim is embed channel, the -2 dim is time channel\n",
    "        shape = x.shape\n",
    "        BSpace_shape = shape[:-2]\n",
    "        C = shape[-1]\n",
    "        permute_order = [0,-1] + list(range(1,len(shape)-1))\n",
    "        x = x.permute(*permute_order)#-->(B, *Space,T, C)-->(B, C, *Space,T)\n",
    "        x = self.avg(F.pad(x,self.pad, mode='replicate'))\n",
    "        permute_order = [0] + list(range(2,len(shape))) + [1]\n",
    "        x = x.permute(*permute_order)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2193e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "layer = moving_avg_spacetime((5,3,2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c937ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64, 6, 7])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(1,32,64,6,7)\n",
    "layer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548cafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.physics_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f35d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.afnonet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245af06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605c0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=get_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a877f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = AFNONet((32,64),2,265,20,depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081a6933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h intervel: 32 , w intervel: 64\n",
      "please notice we will using dt= 3600*1 as intertime\n"
     ]
    }
   ],
   "source": [
    "layer = DirectSpace_Feature_Model(args,backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "995b4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.randn(1,4,5,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285eced2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5915, grad_fn=<StdMeanBackward0>),\n",
       " tensor(-0.0057, grad_fn=<StdMeanBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(layer(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "119b2ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 64])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = Second_Derivative_Layer()\n",
    "\n",
    "a=torch.randn(1,1,32,64)\n",
    "\n",
    "layer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "083c6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=2\n",
    "P=4\n",
    "a=torch.randn(B,P,3,32,64).cuda()\n",
    "layer=  First_Derivative_Layer(dim=3).cuda()\n",
    "runtime_weight=layer.runtime_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a49e635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.8 µs ± 130 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = torch.conv3d(a.flatten(0,1).unsqueeze(1),runtime_weight).reshape(*a.shape[:-1],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe1a2493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.1 µs ± 1.63 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x2 = torch.conv1d(a.flatten(0,-2).unsqueeze(1),runtime_weight[0,0]).reshape(*a.shape[:-1],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55db951f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7120e039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc62104ec40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.scatter(x,y)\n",
    "#plt.scatter([10],[10],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42446069",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_fourier_drive(x, position,pad):\n",
    "\n",
    "    if len(position)==1:position = position[0]\n",
    "    base_len          = np.array(x.shape[position])\n",
    "    interpolate_shape = base_len + (base_len-1)*pad\n",
    "    interpolate_shape = tuple(interpolate_shape)\n",
    "    if isinstance(position,int) or len(position) == 1\n",
    "        x = x.transpose(-1,position)\n",
    "        out_shape = x.shape[:-1]\n",
    "        x = x.reshape(x.size(0),-1,x.size(-1))\n",
    "        b = torch.nn.functional.interpolate(x,interpolate_shape,mode='linear',align_corners=True)\n",
    "        bf = torch.fft.rfft(b,dim=-1)\n",
    "        kbf= bf*torch.fft.rfftfreq(b.size(-1)).reshape(1,1,-1)\n",
    "        kb = torch.fft.irfft(kbf,dim=-1)\n",
    "        index = torch.arange(0,b.size(-1)+1,base_len-1)\n",
    "        kb = kb[...,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0209174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tkinter.messagebox import NO\n",
    "import numpy as np\n",
    "import torch,os,io,socket\n",
    "from torchvision import datasets, transforms\n",
    "hostname = socket.gethostname()\n",
    "from functools import lru_cache\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils.timefeatures import time_features\n",
    "import os\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07efc1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatimelist  = np.arange(np.datetime64(\"1979-01-01\"), np.datetime64(\"2016-01-01\"), np.timedelta64(6, \"h\"))\n",
    "timestamp = time_features(pd.to_datetime(datatimelist)).transpose(1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d452ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(np.datetime64(\"1980-12-31\")).dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebb2999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(datatimelist)[0].dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6cc284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       , -0.5       ],\n",
       "       [-0.23913043, -0.5       ],\n",
       "       [ 0.02173913, -0.5       ],\n",
       "       [ 0.2826087 , -0.5       ],\n",
       "       [-0.5       , -0.49726027],\n",
       "       [-0.23913043, -0.49726027],\n",
       "       [ 0.02173913, -0.49726027],\n",
       "       [ 0.2826087 , -0.49726027],\n",
       "       [-0.5       , -0.49452055],\n",
       "       [-0.23913043, -0.49452055]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp[:10,[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b05b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JCmodels.fourcastnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb59fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AFNONet((32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443ac0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,4,5,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c828a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5, 32, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ae080",
   "metadata": {},
   "source": [
    "#### FEDformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55908ea1",
   "metadata": {},
   "source": [
    "#### complex version AdaptiveFourierNeuralOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331c5ac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96f64f13",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def multiply(input, weights):\n",
    "    return torch.einsum('...bd,bdk->...bk', input, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "acaf839a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "B=1\n",
    "h=32;w=64;C=2\n",
    "num_blocks=1\n",
    "block_size=2\n",
    "\n",
    "w1 = torch.randn(num_blocks, block_size, block_size, dtype=torch.cfloat)\n",
    "b1 = torch.randn(num_blocks, block_size, dtype=torch.cfloat)\n",
    "w2 = torch.randn(num_blocks, block_size, block_size, dtype=torch.cfloat)\n",
    "b2 = torch.randn(num_blocks, block_size, dtype=torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cbfa8d54",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def original_realize(x,w1,b1,w2,b2):\n",
    "    x = torch.fft.rfft2(x, dim=(1, 2), norm='ortho');\n",
    "    x = x.reshape(B, x.shape[1], x.shape[2], num_blocks, block_size)\n",
    "    x_real = F.relu(multiply(x.real, w1.real) - multiply(x.imag, w1.imag) + b1.real, inplace=True)\n",
    "    x_imag = F.relu(multiply(x.real, w1.imag) + multiply(x.imag, w1.real) + b1.imag, inplace=True)\n",
    "    x = torch.stack([x_real, x_imag], dim=-1)\n",
    "    x = torch.view_as_complex(x)\n",
    "    return x\n",
    "\n",
    "def complex_version_realize(x,w1,b1,w2,b2):\n",
    "    x = torch.fft.rfft2(x, dim=(1, 2), norm='ortho');\n",
    "    x = x.reshape(B, x.shape[1], x.shape[2], num_blocks, block_size)\n",
    "    x = multiply(x,w1)+b1\n",
    "    x = nonlinear_activate(x)\n",
    "    return x\n",
    "x  = torch.randn(B, h, w, C)\n",
    "y1 = original_realize(x,w1,b1,w2,b2)\n",
    "y2 = complex_version_realize(x,w1,b1,w2,b2)\n",
    "torch.dist(y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d2f8cb3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from model.afnonet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ccd53",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### AFNONet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "587d11df",
   "metadata": {
    "code_folding": [
     0,
     1,
     6,
     70,
     103,
     132,
     185,
     192,
     203,
     206,
     213,
     223,
     226,
     242
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PartReLU_Complex(nn.Module):\n",
    "    def forward(self,x):\n",
    "        F.relu(x.real, inplace=True)\n",
    "        F.relu(x.imag, inplace=True)\n",
    "        return x\n",
    "\n",
    "class AdaptiveFourierNeuralOperator(nn.Module):\n",
    "    def __init__(self, dim, img_size, fno_blocks=4,fno_bias=True, fno_softshrink=False,nonlinear_activate=PartReLU_Complex()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = dim\n",
    "        self.img_size   = img_size\n",
    "        self.num_blocks = fno_blocks\n",
    "        self.block_size = self.hidden_size // self.num_blocks\n",
    "        assert self.hidden_size % self.num_blocks == 0\n",
    "\n",
    "        self.scale = 0.02\n",
    "        self.w1 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              self.block_size, dtype=torch.cfloat))\n",
    "        self.b1 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              dtype=torch.cfloat))\n",
    "        self.w2 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              self.block_size, dtype=torch.cfloat))\n",
    "        self.b2 = torch.nn.Parameter(self.scale * torch.randn(self.num_blocks, self.block_size, \n",
    "                                                              dtype=torch.cfloat))\n",
    "        self.relu = nonlinear_activate\n",
    "\n",
    "        if fno_bias:\n",
    "            self.bias = nn.Conv1d(self.hidden_size, self.hidden_size, 1)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.softshrink = fno_softshrink\n",
    "\n",
    "    def multiply(self, input, weights):\n",
    "        return torch.einsum('...bd,bdk->...bk', input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape    \n",
    "        bias = self.bias(x.permute(0, 2, 1)).permute(0, 2, 1) if self.bias else 0\n",
    "        #timer.restart(2)\n",
    "        x = x.reshape(B, *self.img_size, C)\n",
    "        fft_dim = tuple(range(1,len(self.img_size)+1))\n",
    "        print(fft_dim)\n",
    "        #timer.record('reshape1','filter',2)\n",
    "        print(x.shape)\n",
    "        x = torch.fft.rfftn(x, dim=fft_dim, norm='ortho');\n",
    "        #timer.record('rfft2','filter',2)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(*x.shape[:-1], self.num_blocks, self.block_size)\n",
    "        #timer.record('reshape2','filter',2)\n",
    "        x = self.multiply(x,self.w1)+self.b1\n",
    "        x = self.relu(x)\n",
    "        x = self.multiply(x,self.w2)+self.b2\n",
    "        x = F.softshrink(x, lambd=self.softshrink) if self.softshrink else x\n",
    "        #with torch.cuda.amp.autocast(enabled=False):\n",
    "        #x = x.float()   \n",
    "        #x = torch.view_as_complex(x)\n",
    "        #timer.record('reset','filter',2)\n",
    "        x = x.flatten(-2,-1)\n",
    "        #timer.record('reshape3','filter',2)\n",
    "        print(x.shape)\n",
    "        x = torch.fft.irfftn(x, s=self.img_size,dim=fft_dim, norm='ortho')\n",
    "        print(x.shape)\n",
    "        #x = x.half()\n",
    "        #timer.record('irfft2','filter',2)\n",
    "        x = x.reshape(B, N, C)\n",
    "        #timer.record('reshape4','filter',2)\n",
    "        return x + bias\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, mlp_ratio=4., drop=0., drop_path=0., act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm, region_shape=(14,8), fno_blocks=3,double_skip=False, fno_bias=False, fno_softshrink=False):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.filter = AdaptiveFourierNeuralOperator(dim, region_shape,fno_blocks=fno_blocks,fno_bias=fno_bias,fno_softshrink=fno_softshrink)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "        self.double_skip = double_skip\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        #timer.restart(1)\n",
    "        x = self.norm1(x)\n",
    "        #timer.record('norm1','forward_features',1)\n",
    "        x = self.filter(x)\n",
    "        #timer.record('filter','forward_features',1)\n",
    "        if self.double_skip:\n",
    "            x += residual\n",
    "            residual = x;\n",
    "        #timer.record('residual','forward_features',1)\n",
    "        x = self.norm2(x)\n",
    "        #timer.record('norm2','forward_features',1)\n",
    "        x = self.mlp(x)\n",
    "        #timer.record('mlp','forward_features',1)\n",
    "        x = self.drop_path(x)\n",
    "        #timer.record('drop_path','forward_features',1)\n",
    "        x += residual\n",
    "        #timer.record('residual','forward_features',1)\n",
    "        return x\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=None, patch_size=8, in_chans=13, embed_dim=768):\n",
    "        super().__init__()\n",
    "\n",
    "        if img_size is None:raise KeyError('img is None')\n",
    "        patch_size   = [patch_size]*len(img_size) if isinstance(patch_size,int) else patch_size\n",
    "        \n",
    "        num_patches=1\n",
    "        out_size=[]\n",
    "        for i_size,p_size in zip(img_size,patch_size):\n",
    "            if p_size%i_size:\n",
    "                num_patches*=i_size// p_size\n",
    "                out_size.append(i_size// p_size)\n",
    "            else:\n",
    "                raise NotImplementedError(f\"the patch size ({patch_size}) cannot divide the img size {img_size}\")\n",
    "        self.img_size    = tuple(img_size)\n",
    "        self.patch_size  = tuple(patch_size)\n",
    "        self.num_patches = num_patches\n",
    "        self.out_size    = tuple(out_size)\n",
    "        conv_engine = [nn.Conv1d,nn.Conv2d,nn.Conv3d]\n",
    "        self.proj   = conv_engine[len(img_size)-1](in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, = x.shape[:2]\n",
    "        inp_size = x.shape[2:]\n",
    "        assert tuple(inp_size) == self.img_size, f\"Input image size ({inp_size}) doesn't match model set size ({self.img_size}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class AFNONet(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, patch_size=8, in_chans=20, out_chans=20, embed_dim=768, depth=12, mlp_ratio=4.,\n",
    "                 uniform_drop=False, drop_rate=0., drop_path_rate=0., norm_layer=None,\n",
    "                 dropcls=0, checkpoint_activations=False, fno_blocks=3,double_skip=False,\n",
    "                 fno_bias=False, fno_softshrink=False,debug_mode=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert img_size is not None\n",
    "        self.checkpoint_activations=checkpoint_activations\n",
    "        self.embed_dim = embed_dim\n",
    "        norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)\n",
    "        self.img_size = img_size\n",
    "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches      = self.patch_embed.num_patches\n",
    "        patch_size       = self.patch_embed.patch_size\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        self.final_shape = self.patch_embed.out_size\n",
    "\n",
    "        if uniform_drop:\n",
    "            dpr = [drop_path_rate for _ in range(depth)]  # stochastic depth decay rule\n",
    "        else:\n",
    "            dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "\n",
    "        self.blocks = nn.ModuleList([Block(dim=embed_dim, mlp_ratio=mlp_ratio, drop=drop_rate,\n",
    "                                           drop_path=dpr[i], \n",
    "                                           norm_layer=norm_layer,\n",
    "                                           region_shape=self.final_shape,\n",
    "                                           double_skip=double_skip,\n",
    "                                           fno_blocks=fno_blocks,\n",
    "                                           fno_bias=fno_bias,\n",
    "                                           fno_softshrink=fno_softshrink) for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # Representation layer\n",
    "        # self.num_features = out_chans * img_size[0] * img_size[1]\n",
    "        # self.representation_size = self.num_features * 8\n",
    "        # self.pre_logits = nn.Sequential(OrderedDict([\n",
    "        #     ('fc', nn.Linear(embed_dim, self.representation_size)),\n",
    "        #     ('act', nn.Tanh())\n",
    "        # ]))\n",
    "        conf_list = [{'kernel_size':[],'stride':[],'padding':[]},\n",
    "                     {'kernel_size':[],'stride':[],'padding':[]},\n",
    "                     {'kernel_size':[],'stride':[],'padding':[]}]\n",
    "        conv_set = {8:[[2,2,0],[2,2,0],[2,2,0]],\n",
    "                    4:[[2,2,0],[3,1,1],[2,2,0]],\n",
    "                    2:[[3,1,1],[3,1,1],[2,2,0]],\n",
    "                    1:[[3,1,1],[3,1,1],[3,1,1]],\n",
    "                   }\n",
    "        for patch in patch_size:\n",
    "            for slot in range(len(conf_list)):\n",
    "                conf_list[slot]['kernel_size'].append(conv_set[patch][slot][0])\n",
    "                conf_list[slot]['stride'].append(conv_set[patch][slot][1])\n",
    "                conf_list[slot]['padding'].append(conv_set[patch][slot][2])\n",
    "\n",
    "        transposeconv_engine = [nn.ConvTranspose1d,nn.ConvTranspose2d,nn.ConvTranspose3d][len(img_size)-1]\n",
    "        self.pre_logits = nn.Sequential(OrderedDict([\n",
    "            ('conv1', transposeconv_engine(embed_dim, out_chans*16, **conf_list[0])),\n",
    "            ('act1', nn.Tanh()),\n",
    "            ('conv2', transposeconv_engine(out_chans*16, out_chans*4, **conf_list[1])),\n",
    "            ('act2', nn.Tanh())\n",
    "        ]))\n",
    "\n",
    "        # Generator head\n",
    "        # self.head = nn.Linear(self.representation_size, self.num_features)\n",
    "        self.head = transposeconv_engine(out_chans*4, out_chans, **conf_list[2])\n",
    "\n",
    "        if dropcls > 0:\n",
    "            print('dropout %.2f before classifier' % dropcls)\n",
    "            self.final_dropout = nn.Dropout(p=dropcls)\n",
    "        else:\n",
    "            self.final_dropout = nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        self.apply(self._init_weights)\n",
    "        self.debug_mode=debug_mode\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        x += self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        if not self.checkpoint_activations:\n",
    "            for blk in self.blocks:\n",
    "                x = blk(x)\n",
    "        else:\n",
    "            x = checkpoint_sequential(self.blocks, 4, x)\n",
    "\n",
    "        x = self.norm(x).transpose(1, 2);print(x.shape)\n",
    "        x = torch.reshape(x, [-1, self.embed_dim, *self.final_shape])\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### we assume always feed the tensor (B, p*z, h, w)\n",
    "        B, P ,h, w = x.shape\n",
    "        x = x.reshape(B,-1,*self.img_size)\n",
    "        #timer.restart(level=0)\n",
    "        x = self.forward_features(x)\n",
    "        #timer.record('forward_features',level=0)\n",
    "        x = self.final_dropout(x)\n",
    "        #timer.record('final_dropout',level=0)\n",
    "        x = self.pre_logits(x)\n",
    "        #timer.record('pre_logits',level=0)\n",
    "        x = self.head(x)\n",
    "        #timer.record('head',level=0)\n",
    "        x = x.reshape(B,P,h,w)\n",
    "        #timer.show_stat()\n",
    "        #print(\"============================\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "50c91758",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = AFNONet(img_size=[10,32,64],patch_size=(1,8,8),depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "094685c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(1,20,10,32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "119f0892",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1,3,4,32,64).flatten(1,2)\n",
    "torch.dist(a.reshape(1,-1,4,32,64).reshape(1,12,32,64),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2fc73c64",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1,12,32,64)\n",
    "torch.dist(a.reshape(1,3,4,32,64).reshape(1,-1,32,64),a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e691946",
   "metadata": {},
   "source": [
    "##### EulerEquationModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce2f336",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class EulerEquationModel2(nn.Module):\n",
    "    def __init__(self, args, backbone):\n",
    "        super().__init__()\n",
    "        self.Dx= First_Derivative_Layer(position=-1, dim=3, mode=2)\n",
    "        self.Dy= First_Derivative_Layer(position=-2, dim=3, mode=2)\n",
    "        self.Dz= First_Derivative_Layer(position=-3, dim=3, mode=1)\n",
    "        self.thermal_factor  = nn.Parameter(torch.randn(3).reshape(1,3,1,1))\n",
    "        self.alpha = nn.Parameter(torch.randn(1))\n",
    "        #self.p_list         = nn.Parameter(torch.Tensor([10,8.5,5]).reshape(1,3,1,1),requires_grad=False)\n",
    "        self.backbone =  backbone\n",
    "        self.monitor = True\n",
    "    def forward(self, Field):\n",
    "        # u^{t+1} &= u^{t} + F_x - \\nabla (Vu)  + u \\nabla\\cdot V - \\partial_x\\phi\\\\\n",
    "        # v^{t+1} &= v^{t} + F_y - \\nabla (Vv)  + v \\nabla\\cdot V - \\partial_y\\phi\\\\\n",
    "        # T^{t+1} &= T^{t} + Q/C_v + \\frac{RT}{C_pp}\\omega  - \\nabla (VT) +T \\nabla\\cdot V\\\\\n",
    "        # \\phi^{t+1}&=\\phi^{t} + wg  - \\nabla (V\\phi)+ \\phi \\nabla\\cdot V \\\\\n",
    "        # 0&\\approx \\nabla\\cdot V\n",
    "        # input -> Field  = [u ,v, T, p] --> (Batch, 4, z, y ,x)\n",
    "        # need generate unknown data [Fx, Fy , Q, W, o]\n",
    "        b, si_z, i_y, i_x = Field.shape\n",
    "        s=4\n",
    "        i_z= si_z//4\n",
    "        MachineLearningPart = self.backbone(Field).reshape(b, s+1, i_z, i_y, i_x) #(Batch, 5, z, y ,x)\n",
    "        ExternalForce = MachineLearningPart[:,:4] #(Batch, 4, z, y ,x)\n",
    "        o = MachineLearningPart[:,4:5] #(Batch, 1, z, y ,x)\n",
    "        Field = Field.reshape(b, s, i_z, i_y,  i_x) #(Batch, 5, z, y ,x)\n",
    "        u = Field[:,0:1]#(Batch, 1, z, y ,x)\n",
    "        v = Field[:,1:2]#(Batch, 1, z, y ,x)\n",
    "        T = Field[:,2:3]#(Batch, 1, z, y ,x)\n",
    "        p = Field[:,3:4]#(Batch, 1, z, y ,x)\n",
    "        V = torch.cat([u,v,o],1)#(Batch, 3, z, y ,x)\n",
    "        Nabla_cdot_V = (self.Dx(u[:,0]) + self.Dy(v[:,0]) + self.Dz(o[:,0])).unsqueeze(1)#(Batch, 1, z, y ,x)\n",
    "        Nabla_V_Field= Nabla_cdot_V*Field #(Batch, 4, z, y ,x)\n",
    "        Vphysics     = torch.stack([V*u,V*v,V*T,V*p],1)#(Batch,4, 3, z, y ,x)\n",
    "        Vphysics_dx = self.Dx(Vphysics[:,:,0].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        Vphysics_dy = self.Dy(Vphysics[:,:,1].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        Vphysics_dz = self.Dz(Vphysics[:,:,2].flatten(0,1)).reshape(Field.shape)#(Batch, 4, z, y ,x)\n",
    "        PhysicsPart = -Vphysics_dx - Vphysics_dy - Vphysics_dz + Nabla_V_Field #(Batch,4,z, y ,x)\n",
    "        InteractionPart= torch.stack([self.Dx(p[:,0]),\n",
    "                                      self.Dy(p[:,0]),\n",
    "                                      self.thermal_factor*T[:,0]*o[:,0]],1)#(Batch,3,z, y ,x)\n",
    "        InteractionPart= F.pad(InteractionPart,(0,0,0,0,0,0,0,1)) #(Batch,4,z, y ,x)\n",
    "        Delta_Fd     = ExternalForce + self.alpha*(PhysicsPart + InteractionPart)\n",
    "        Field        = Field+ Delta_Fd\n",
    "        constrain    = Nabla_V_Field\n",
    "        if not self.monitor:\n",
    "            return Field.flatten(1,2),(constrain**2).mean()\n",
    "        else:\n",
    "            return Field.flatten(1,2),(constrain**2).mean(),{\"ExternalForceFactor\":(ExternalForce**2).mean().item(),\n",
    "                                                             \"PhysicsDrivenFactor\":(PhysicsPart**2).mean().item(),\n",
    "                                                             \"InteractionPart\":(InteractionPart**2).mean().item(),\n",
    "                                                             \"alpha\":self.alpha.item()}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
